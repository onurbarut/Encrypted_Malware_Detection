import os
import json
import time as t
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.pipeline import Pipeline
from sklearn import svm, datasets, metrics, preprocessing
from sklearn.neural_network import MLPClassifier
from sklearn.utils.multiclass import unique_labels
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_selection import SelectPercentile, SelectKBest, chi2
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score

from utils.helper2 import *

dataset = "./data/NetML" # "./data/NetML" or "./data/CICIDS2017" or "./data/non-vpn2016"
anno = "top" # or "mid" or "fine"
#submit = "both" # or "test-std" or "test-challenge"

# Assign variables
training_set = dataset+"/2_training_set"
training_anno_file = dataset+"/2_training_annotations/2_training_anno_"+anno+".json.gz"
test_set = dataset+"/1_test-std_set"
challenge_set = dataset+"/0_test-challenge_set"

# TLS, DNS, HTTP features included?
TLS , DNS, HTTP = {}, {}, {}
TLS['tlsOnly'] = True # returns
TLS['use'] = True
TLS['n_common_client'] = 10
TLS['n_common_server'] = 5
#
DNS['use'] = False
##
##
#
HTTP['use'] = False
##
##


# Get training data in np.array format
annotationFileName = dataset+"/2_training_annotations/2_training_anno_top.json.gz"
feature_names, ids, Xtrain, labels, class_label_pair = read_dataset(training_set, annotationFileName=annotationFileName, TLS=TLS, class_label_pairs=None)


# Drop flows if either num_pkts_in or num_pkts_out < 1
df = pd.DataFrame(data=Xtrain, columns=feature_names)
df['label'] = labels
isFiltered = df['num_pkts_in'] < 1
f_df = df[~isFiltered]
isFiltered = f_df['num_pkts_out'] < 1
f_df = f_df[~isFiltered]
target = f_df.pop('label')

# Train RF Model
class_names = sorted(list(class_label_pair.keys()))

#
# #############################################################################
# Plot the cross-validation score as a function of percentile of features
score_means = list()
score_stds = list()
topN = 50

# Save best top K features
Xtrain, Xtest, ytrain, ytest = train_test_split(f_df.values, target.values, test_size=0.2, random_state=10, shuffle = True, stratify = target)
print("Extracting %d best features by a chi-squared test to csv file" %
      topN)
t0 = t.time()
ch2 = SelectKBest(chi2, k=topN)
X_train = ch2.fit_transform(Xtrain, ytrain)
X_test = ch2.transform(Xtest)
# keep selected feature names
feature_names = [f_df.columns[i] for i
                 in ch2.get_support(indices=True)]

to_drop = [feature for feature in f_df.columns if feature not in feature_names]

f_df = f_df.drop(to_drop, axis=1)
f_df['label'] = target
f_df.to_csv("_enc_filtered_top{}.csv".format(topN), index=False)